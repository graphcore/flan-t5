<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://user-images.githubusercontent.com/81682248/226963550-21eaaf59-ee3c-49a9-8e75-b76d740ddd09.png">
  <img width="300" alt="Graphcore logo" src="https://user-images.githubusercontent.com/81682248/226963440-9cae0ac4-ebf5-407a-9870-5679e434cada.png">
</picture>

# Flan-T5 on IPUs

![Flan-T5 header](flan-t5.png.webp)

Flan-T5 is the fine-tuned version of the T5 language model. Compared to T5, Flan-T5 has been fine-tuned on more than 1,000 additional tasks. This makes Flan-T5 a more efficient, open-source alternative to models like GPT-3 and GPT-4.

Graphcore's IPU (Intelligence Processing Unit) is a completely new kind of massively parallel processor to accelerate machine intelligence. Developers can access advanced, cost-efficient IPU compute on-demand in the cloud for building, fine-tuning and deploying AI models such as Flan-T5.


## Flan-T5 notebooks powered by IPUs

| Notebook | Framework | Type | Try for Free
| ------------- | ------------- | ------------- | ------------- |
| Flan-T5 is (probably) all you need | Hugging Face | Inference | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://ipu.dev/4qFXZd)

This notebook demonstrates using Flan-T5 for some common NLP tasks like text generation, sentiment analysis, advanced named entity recognition, question answering, intent classification, summarization and text classification.

Note: If you have an existing Flan-T5 application based on Hugging Face, you need to change just two lines of code to be able to run on IPUs.

## Flan-T5 resources

* [GitHub code](https://github.com/graphcore/Gradient-HuggingFace/tree/main/natural-language-processing)
* Hugging Face models
  * [google/flan-t5-large](https://huggingface.co/google/flan-t5-large)
  * [google/flan-t5-xl](https://huggingface.co/google/flan-t5-xl)
* [Overview blog](https://www.graphcore.ai/posts/flan-t5-sweet-results-with-the-smaller-more-efficient-llm)
* [How-to walkthrough blog](https://www.graphcore.ai/posts/running-flan-t5-xl-inference-in-float16-for-ipu-how-we-did-it)
* [Original paper](https://arxiv.org/abs/2210.11416)

To find out more about running Flan-T5 on IPUs, or speak to an expert, please feel free to [contact us](https://www.graphcore.ai/contact).

## IPU community

Join our growing community and interact with AI experts, IPU developers and researchers. Hear the latest IPU news and get access to our newest models.

[![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)
